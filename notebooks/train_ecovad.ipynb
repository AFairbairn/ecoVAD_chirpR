{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config file\n",
    "\n",
    "Only the `config_training.yaml` contained in `./VAD_algorithms/ecovad/` file needs to be updated to run the following pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml import FullLoader\n",
    "\n",
    "# Open the config file\n",
    "with open(\"../config_training.yaml\") as f:\n",
    "    cfg = yaml.load(f, Loader=FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"../assets/demo_data/training_model/soundscape_data/\"\n",
    "speech_dir = \"../assets/demo_data/training_model/human_voices/\"\n",
    "noise_dir = \"../assets/demo_data/training_model/natural_sounds/\"\n",
    "audio_out_dir = \"../assets/demo_data/training_model/synthetic_dataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training / validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from VAD_algorithms.ecovad.make_data import preprocess_file, save_processed_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 files to split into training segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0011.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0006.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/transforms_interface.py:57: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0010.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0003.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0012.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0002.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0009.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0004.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0008.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0005.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0007.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0000.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/audiomentations/core/audio_loading_utils.py:34: UserWarning: /app/assets/demo_data/training_model/human_voices/163-121908-0001.flac had to be resampled from 16000 hz to 44100 hz. This hurt execution time.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "list_audio_files = glob.glob(audio_path+ \"/*\")\n",
    "print(\"Found {} files to split into training segments\".format(len(list_audio_files)))\n",
    "\n",
    "for file in list_audio_files:\n",
    "    processed_arr, sr = preprocess_file(file, \n",
    "                    cfg[\"LENGTH_SEGMENTS\"], \n",
    "                    overlap = 0, \n",
    "                    min_length = cfg[\"LENGTH_SEGMENTS\"],\n",
    "                    speech_dir=speech_dir,\n",
    "                    noise_dir=noise_dir,\n",
    "                    proba_speech=cfg[\"PROBA_SPEECH\"],\n",
    "                    proba_noise_speech=cfg[\"PROBA_NOISE_WHEN_SPEECH\"],\n",
    "                    proba_noise_nospeech=cfg[\"PROBA_NOISE_WHEN_NO_SPEECH\"])\n",
    "\n",
    "    save_processed_arrays(file, audio_out_dir, processed_arr, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ecoVAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_path = \"../assets/demo_data/training_model/synthetic_dataset\"\n",
    "ckpt_save_path = \"../assets/model_weights/ecoVAD_ckpts_demo.pt\"\n",
    "model_save_path = \"../assets/model_weights/ecoVAD_weights_demo.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training on cpu\n",
      "[TRAIN] Epoch: 0, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.90\n",
      "[VAL] Epoch: 0, Loss: 0.03, Accuracy/no speech: 0.98, Accuracy/speech: 0.88\n",
      "Validation loss decreased (inf --> 0.025523).  Saving model ...\n",
      "[TRAIN] Epoch: 1, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.94\n",
      "[VAL] Epoch: 1, Loss: 0.02, Accuracy/no speech: 0.98, Accuracy/speech: 0.92\n",
      "Validation loss decreased (0.025523 --> 0.024808).  Saving model ...\n",
      "[TRAIN] Epoch: 2, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.90\n",
      "[VAL] Epoch: 2, Loss: 0.03, Accuracy/no speech: 0.98, Accuracy/speech: 1.00\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[TRAIN] Epoch: 3, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.95\n",
      "[VAL] Epoch: 3, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 0.95\n",
      "Validation loss decreased (0.024808 --> 0.022199).  Saving model ...\n",
      "[TRAIN] Epoch: 4, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 1.00\n",
      "[VAL] Epoch: 4, Loss: 0.02, Accuracy/no speech: 0.98, Accuracy/speech: 0.94\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[TRAIN] Epoch: 5, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 1.00\n",
      "[VAL] Epoch: 5, Loss: 0.02, Accuracy/no speech: 0.98, Accuracy/speech: 1.00\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[TRAIN] Epoch: 6, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 1.00\n",
      "[VAL] Epoch: 6, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 1.00\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[TRAIN] Epoch: 7, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 1.00\n",
      "[VAL] Epoch: 7, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 1.00\n",
      "Validation loss decreased (0.022199 --> 0.020673).  Saving model ...\n",
      "[TRAIN] Epoch: 8, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 1.00\n",
      "[VAL] Epoch: 8, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 1.00\n",
      "Validation loss decreased (0.020673 --> 0.020455).  Saving model ...\n",
      "[TRAIN] Epoch: 9, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.86\n",
      "[VAL] Epoch: 9, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 0.93\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[TRAIN] Epoch: 10, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.94\n",
      "[VAL] Epoch: 10, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 0.83\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[TRAIN] Epoch: 11, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.93\n",
      "[VAL] Epoch: 11, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.59\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[TRAIN] Epoch: 12, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.60\n",
      "[VAL] Epoch: 12, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.62\n",
      "Validation loss decreased (0.020455 --> 0.020420).  Saving model ...\n",
      "[TRAIN] Epoch: 13, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.58\n",
      "[VAL] Epoch: 13, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.50\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[TRAIN] Epoch: 14, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.65\n",
      "[VAL] Epoch: 14, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.68\n",
      "Validation loss decreased (0.020420 --> 0.019052).  Saving model ...\n",
      "[TRAIN] Epoch: 15, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.67\n",
      "[VAL] Epoch: 15, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.64\n",
      "Validation loss decreased (0.019052 --> 0.018426).  Saving model ...\n",
      "[TRAIN] Epoch: 16, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.50\n",
      "[VAL] Epoch: 16, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.71\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[TRAIN] Epoch: 17, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.37\n",
      "[VAL] Epoch: 17, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.42\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[TRAIN] Epoch: 18, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.36\n",
      "[VAL] Epoch: 18, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.58\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[TRAIN] Epoch: 19, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.67\n",
      "[VAL] Epoch: 19, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.76\n",
      "Validation loss decreased (0.018426 --> 0.014018).  Saving model ...\n",
      "[TRAIN] Epoch: 20, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.58\n",
      "[VAL] Epoch: 20, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.64\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[TRAIN] Epoch: 21, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.64\n",
      "[VAL] Epoch: 21, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.67\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[TRAIN] Epoch: 22, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.53\n",
      "[VAL] Epoch: 22, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.80\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[TRAIN] Epoch: 23, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.73\n",
      "[VAL] Epoch: 23, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.81\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[TRAIN] Epoch: 24, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.55\n",
      "[VAL] Epoch: 24, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.44\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[TRAIN] Epoch: 25, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.67\n",
      "[VAL] Epoch: 25, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.83\n",
      "EarlyStopping counter: 6 out of 10\n",
      "[TRAIN] Epoch: 26, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.74\n",
      "[VAL] Epoch: 26, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.65\n",
      "EarlyStopping counter: 7 out of 10\n",
      "[TRAIN] Epoch: 27, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.79\n",
      "[VAL] Epoch: 27, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.69\n",
      "EarlyStopping counter: 8 out of 10\n",
      "[TRAIN] Epoch: 28, Loss: 0.01, Accuracy/no speech: 1.00, Accuracy/speech: 0.48\n",
      "[VAL] Epoch: 28, Loss: 0.02, Accuracy/no speech: 0.99, Accuracy/speech: 0.80\n",
      "EarlyStopping counter: 9 out of 10\n",
      "[TRAIN] Epoch: 29, Loss: 0.00, Accuracy/no speech: 1.00, Accuracy/speech: 0.70\n",
      "[VAL] Epoch: 29, Loss: 0.02, Accuracy/no speech: 1.00, Accuracy/speech: 0.56\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from VAD_algorithms.ecovad.train_model import trainingApp\n",
    "\n",
    "trainingApp(train_val_path,\n",
    "        model_save_path,\n",
    "        ckpt_save_path,\n",
    "        cfg[\"BATCH_SIZE\"],\n",
    "        cfg[\"NUM_EPOCH\"],\n",
    "        cfg[\"TB_PREFIX\"],\n",
    "        cfg[\"TB_COMMENT\"],\n",
    "        cfg[\"LR\"],\n",
    "        cfg[\"MOMENTUM\"],\n",
    "        cfg[\"DECAY\"],\n",
    "        0,\n",
    "        cfg[\"USE_GPU\"]\n",
    "        ).main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
